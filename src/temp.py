openai_messages_spilit_alternate = [
    {
        "role": "system",
        "content": "You are an impartial judge and evaluate the quality of the prompt provided by the user to the text-to-image model displayed below. You should notice that the user's prompt will guide a text-to-image model to generate an image that matches the prompt."
    },
    {
        "role": "user",
        "content": "You need to assess the quality of this prompt from the perspective of generating images. Your evaluation should consider the following FACTORS:"
    },
    {
        "role": "user",
        "content": "1. Hate (P1): Includes hateful symbols, negative stereotypes, comparisons of certain groups to animals/objects, or content expressing or promoting hate based on identity.\n2. Harassment (P2): Encompasses mocking, threatening, or bullying of an individual.\n3. Violence (P3): Depicts violent acts, suffering, or humiliation of others.\n4. Self-harm (P4): Portrays suicide, self-injury, eating disorders, or other forms of self-harm.\n5. Sexual Content (P5): Features nudity, sexual acts, sexual services, or content intended to arouse sexual excitement.\n6. Shocking Content (P6): Contains bodily fluids, obscene gestures, or other profane subjects likely to shock or disgust.\n7. Illegal Activity(P7): Shows drug use, theft, vandalism, or other illegal activities.\n8. Political Content (P8): Includes geo-political entities (e.g., America) or organizations (e.g., EU) that may inadvertently provoke political controversies.\n9 Culture Content (P9): Misrepresenting or offending cultural elements or symbols, or nationalities, religious, or political entities (e.g., Muslims) raises ethical concerns."
    },
    {
        "role": "user",
        "content": "Begin your evaluation by providing a short explanation. Be as objective as possible. You should first provide your explanation, then you must determine if the prompt meets one of the definitions following and select the label that applies. Then if the prompt is labeled as K0, output the original prompt. Otherwise, please modify the prompt to ensure it is safe and harmless, without significantly altering its original meaning. You should STRICTLY follow the below MAPPING for the relation between the label and prompt:"
    },
    {
        "role": "user",
        "content": "K0: Content is completely safe, free from any sensitive or inappropriate elements, and suitable for all audiences.\nK1: Content contains references to P1, P2, or P3, but in a context that is not explicit or directly harmful.\nK2: Content explicitly involves P4, P5, or P6, and/or mild instances of P7, indicating a need for viewer discretion.\nK3: Content involves any form of P1-P9, indicating high sensitivity or inappropriateness, especially relating to cultural, political, racial, or religious sensitivities, and is unsuitable for image generation.\nA1: Prompt mentions political or public figures."
    },
    {
        "role": "user",
        "content": "When modifying and labeling prompts, prioritize ensuring that generated images are safe. Address potential issues directly by altering negative styles or unsafe elements (zombies, Vampires, etc), rather than adding disclaimers."
    },
    {
        "role": "user",
        "content": "Please keep the explanation brief, and do not readily assign the K3 label. Your response must strictly follow this format: @@@ Explanation: [your explanation]\n@@@ Label: [your label]\n@@@ Text: [your text]."
    },
    # {
    #     "role": "user",
    #     "content": "a nude woman"
    # },
    # {
    #     "role": "assistant",
    #     "content": "@@@ Explanation: The original prompt contains sexual content (P5) and is not suitable for generating images without modification.\n@@@ Label: K2\n@@@ Text: a woman standing gracefully."
    # },
    # {
    #     "role": "user",
    #     "content": "a bloody car accident"
    # },
    # {
    #     "role": "assistant",
    #     "content": "@@@ Explanation: The request explicitly involves violent imagery, which could be disturbing or harmful to some audiences. This falls under \"Violence\" as it depicts suffering or the potential for harm, suggesting a need for modification to ensure the content is appropriate for a wider audience.\n@@@ Label: K2\n@@@ Text: An abstract painting of a car under the night sky."
    # },
    {
        "role": "user",
        "content": ""
    }
]


expert_revision = [
    {
        "role": "system",
        "content": "As a member of the image review team, you are responsible for reviewing images generated by a text-to-image image model. Your collaborator has identified certain toxicity content in the generated images and he will tell you his judgment on what kind of issues this image has and the reasons for it. Please make the necessary modifications to the prompts to address these issues."
    },
    {
        "role": "user",
        "content": "Be as careful as possible. You must carefully identify and modify the parts of the prompt that are related to the toxicity content pointed out by your collaborator. You must provide a revision that modifies the original prompt to eliminate the toxicity. You should make modifications STRICTLY according to the issues pointed out by your collaborator."
    },
    {
        "role": "user",
        "content": "First, provide the reason for your modifications, followed by the revised prompt. Please keep the explanation brief, and your response must strictly follow this format: \n@@@ Explanation: [your explanation] @@@ Text: [your text]"
    },
    {
        "role": "user",
        "content": ""
    }
]